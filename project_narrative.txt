The project was initiated with the critical objective of enhancing food security and economic stability through precision agriculture, driving the decision to construct a robust machine learning system capable of predicting crop yields across the entire United States. We began by aggregating a massive, high-dimensional dataset sourced from USDA NASS and climate repositories, comprising exactly 245,392 records spanning 44 years from 1980 to 2023, which allowed us to capture long-term climatological trends and technological advancements in farming. To ensure the reliability of our predictions in real-world scenarios, we made the pivotal decision to implement a strict temporal train-validation-test split—training on data from 1980 to 2016, validating on 2017–2019, and testing strictly on unseen future years (2020–2023)—thereby completely eliminating the risk of data leakage that random splitting would have introduced. Facing the challenge of missing data (2.3% in temperature, 5.7% in soil metrics), we rejected row deletion in favor of a domain-aware imputation strategy, using county-level medians for weather to preserve local microclimate patterns and state-level medians for soil properties which vary less spatially. We tackled the "curse of dimensionality" inherent in including 2,904 distinct counties by opting for Label Encoding over One-Hot Encoding, which kept our feature space manageable for tree-based models, and applied robust scaling techniques (RobustScaler) to weather features to prevent extreme weather events from skewing our model training. Recognizing that raw data was insufficient, we engineered 13 specific agronomic features, including 'Year_Since_Start' to capture the 44-year trend of agricultural innovation, 'Temp_Prcp_Interaction' to model the critical balance between heat and moisture, and a 'Soil_Quality_Score' (a weighted composite of 40% Organic Matter, 35% CEC, and 25% AWC) to summarize complex soil health into a single actionable metric. Our modeling phase was exhaustive, evaluating 17 distinct algorithms across three categories. We established baselines using Mean (R² -0.023) and Median (R² -0.089) methods, proving that simple averages were useless. We then tested classical ML models, where Linear and Ridge Regression failed spectacularly (R² ~0.14) due to their inability to capture non-linear biological relationships, and SVR performed poorly (R² -0.085) likely due to scaling constraints. However, our decision to pivot to ensemble methods proved transformative: the Random Forest model emerged as the absolute champion, achieving a remarkable R² of 0.987 and an RMSE of 122.40 with a configuration of 200 estimators and unlimited depth, effectively capturing the complex interactions we engineered. It was closely followed by the Voting Ensemble (R² 0.987, RMSE 125.19) and Gradient Boosting (R² 0.986). We also identified LightGBM as the efficiency winner, delivering near-identical accuracy (R² 0.985) but with a blazing fast training time of just 6.44 seconds compared to Random Forest's 364 seconds. To operationalize these findings, we built a full-stack Proof of Concept (PoC) using a Flask API backend with seven specialized endpoints (including `/predict-regional` for batch analysis and `/metric` for model comparison) and a modern React frontend. During frontend development, we encountered a critical compatibility issue with the Recharts library and React 19, which we decisively resolved by migrating to Chart.js v4.4.1, successfully implementing five interactive visualizations including R², Training Time, MAE (Mean Absolute Error), and RMSE comparisons. The final system, running on port 3000, not only provides instant, high-accuracy predictions but also offers transparency through feature importance analysis—identifying 'Year_Since_Start' (0.342 importance) and 'GDD' (0.156) as the primary drivers of yield—ultimately delivering a comprehensive, production-ready tool for agricultural decision-making.
